import requests
import time
import json
import os
from datetime import datetime, timedelta
from openai import OpenAI


class TwitterAIMonitor:
    """Twitteræ¨æ–‡ç›‘æ§å’ŒAIå¤„ç†å™¨"""
    
    def __init__(self, twitter_api_key: str, llm_url: str, llm_api_key: str, data_dir: str = "data", 
                 dingtalk_webhook: str = "", dingtalk_secret: str = "", enable_dingtalk: bool = False,
                 ai_max_retries: int = 3, ai_timeout: int = 30, ai_max_tokens: int = 1000):
        """
        åˆå§‹åŒ–ç›‘æ§å™¨
        
        :param twitter_api_key: TwitterAPI.io API Key
        :param llm_url: å¤§æ¨¡å‹æ¥å£URL
        :param llm_api_key: å¤§æ¨¡å‹API Key
        :param data_dir: æ•°æ®å­˜å‚¨ç›®å½•
        :param dingtalk_webhook: é’‰é’‰æœºå™¨äººWebhookåœ°å€
        :param dingtalk_secret: é’‰é’‰æœºå™¨äººç­¾åå¯†é’¥
        :param enable_dingtalk: æ˜¯å¦å¯ç”¨é’‰é’‰æ¨é€
        :param ai_max_retries: AIè°ƒç”¨æœ€å¤§é‡è¯•æ¬¡æ•°
        :param ai_timeout: AIè°ƒç”¨è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        :param ai_max_tokens: AIè°ƒç”¨æœ€å¤§tokenæ•°é‡
        """
        self.twitter_api_key = twitter_api_key
        self.llm_client = OpenAI(
            api_key=llm_api_key,
            base_url=llm_url,
        )
        self.data_dir = data_dir
        self.dingtalk_webhook = dingtalk_webhook
        self.dingtalk_secret = dingtalk_secret
        self.enable_dingtalk = enable_dingtalk
        self.ai_max_retries = ai_max_retries
        self.ai_timeout = ai_timeout
        self.ai_max_tokens = ai_max_tokens
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(data_dir, exist_ok=True)
    
    def get_ai_response(self, prompt: str, max_retries: int = None) -> str:
        """
        è°ƒç”¨AIæ¨¡å‹è·å–å“åº”ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶
        
        :param prompt: è¾“å…¥æç¤ºè¯
        :param max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®å€¼
        :return: AIå“åº”å†…å®¹
        """
        if max_retries is None:
            max_retries = self.ai_max_retries
            
        for attempt in range(max_retries):
            try:
                print(f"ğŸ¤– AIè°ƒç”¨å°è¯• {attempt + 1}/{max_retries}")
                
                completion = self.llm_client.chat.completions.create(
                    model="qwen-plus",
                    messages=[
                        {"role": "system", "content": "You are a helpful assistant."},
                        {"role": "user", "content": prompt},
                    ],
                    timeout=self.ai_timeout,  # ä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´
                    max_tokens=self.ai_max_tokens  # ä½¿ç”¨é…ç½®çš„tokenæ•°é‡
                )
                
                response = completion.choices[0].message.content
                if response and response.strip():
                    print(f"âœ… AIè°ƒç”¨æˆåŠŸ (å°è¯• {attempt + 1})")
                    return response
                else:
                    print(f"âš ï¸ AIè¿”å›ç©ºå“åº” (å°è¯• {attempt + 1})")
                    if attempt < max_retries - 1:
                        time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                        continue
                    else:
                        return "AIè¿”å›ç©ºå“åº”ï¼Œè¯·é‡è¯•"
                        
            except Exception as e:
                error_msg = str(e)
                print(f"âŒ AIè°ƒç”¨å‡ºé”™ (å°è¯• {attempt + 1}): {error_msg}")
                
                # æ ¹æ®é”™è¯¯ç±»å‹å†³å®šæ˜¯å¦é‡è¯•
                if "rate limit" in error_msg.lower() or "429" in error_msg:
                    print("ğŸš« é‡åˆ°é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾…åé‡è¯•...")
                    time.sleep(10)  # é¢‘ç‡é™åˆ¶ç­‰å¾…10ç§’
                elif "timeout" in error_msg.lower() or "timed out" in error_msg:
                    print("â° è¯·æ±‚è¶…æ—¶ï¼Œç­‰å¾…åé‡è¯•...")
                    time.sleep(5)  # è¶…æ—¶ç­‰å¾…5ç§’
                elif "invalid api key" in error_msg.lower() or "401" in error_msg:
                    print("ğŸ”‘ APIå¯†é’¥æ— æ•ˆï¼Œåœæ­¢é‡è¯•")
                    return f"APIå¯†é’¥é”™è¯¯: {error_msg}"
                elif "quota exceeded" in error_msg.lower():
                    print("ğŸ’³ APIé…é¢å·²ç”¨å®Œï¼Œåœæ­¢é‡è¯•")
                    return f"APIé…é¢å·²ç”¨å®Œ: {error_msg}"
                elif "data_inspection_failed" in error_msg.lower() or "inappropriate content" in error_msg.lower():
                    print("ğŸš« å†…å®¹å®‰å…¨æ£€æŸ¥å¤±è´¥ï¼Œå°è¯•å†…å®¹æ¸…ç†åé‡è¯•...")
                    # å¯¹äºå†…å®¹å®‰å…¨æ£€æŸ¥å¤±è´¥ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´åé‡è¯•
                    time.sleep(8)  # å†…å®¹å®‰å…¨æ£€æŸ¥å¤±è´¥ç­‰å¾…8ç§’
                    if attempt < max_retries - 1:
                        continue
                    else:
                        return f"å†…å®¹å®‰å…¨æ£€æŸ¥å¤±è´¥: æ¨æ–‡å†…å®¹å¯èƒ½åŒ…å«ä¸å½“å†…å®¹ï¼Œå·²å°è¯•æ¸…ç†ä½†ä»æœ‰é—®é¢˜"
                else:
                    print("â“ æœªçŸ¥é”™è¯¯ï¼Œç­‰å¾…åé‡è¯•...")
                    time.sleep(3)  # å…¶ä»–é”™è¯¯ç­‰å¾…3ç§’
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç»§ç»­é‡è¯•
                if attempt < max_retries - 1:
                    continue
                else:
                    return f"AIå¤„ç†å¤±è´¥: {error_msg}"
        
        return "AIå¤„ç†å¤±è´¥: å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°"
    
    def process_tweet_with_ai(self, tweet_text: str) -> dict:
        """
        ä½¿ç”¨AIå¤„ç†æ¨æ–‡ï¼šç¿»è¯‘ã€è§£è¯»ã€ç”Ÿæˆæ ‡é¢˜
        
        :param tweet_text: æ¨æ–‡å†…å®¹
        :return: åŒ…å«AIå¤„ç†ç»“æœçš„å­—å…¸
        """
        # éªŒè¯æ¨æ–‡å†…å®¹
        if not tweet_text or not tweet_text.strip():
            print("âš ï¸ æ¨æ–‡å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡AIå¤„ç†")
            return {
                'title': 'æ¨æ–‡å†…å®¹ä¸ºç©º',
                'translation': 'æ¨æ–‡å†…å®¹ä¸ºç©º',
                'analysis': 'æ¨æ–‡å†…å®¹ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æ'
            }
        
        # å†…å®¹é¢„å¤„ç†ï¼Œè¿‡æ»¤å¯èƒ½å¯¼è‡´å†…å®¹å®‰å…¨æ£€æŸ¥å¤±è´¥çš„å†…å®¹
        print("ğŸ§¹ æ­£åœ¨è¿›è¡Œå†…å®¹é¢„å¤„ç†...")
        cleaned_text = self.preprocess_tweet_content(tweet_text)
        
        # é™åˆ¶æ¨æ–‡é•¿åº¦ï¼Œé¿å…è¿‡é•¿å†…å®¹å¯¼è‡´AIå¤„ç†å¤±è´¥
        if len(cleaned_text) > 1000:
            print(f"âš ï¸ æ¨æ–‡å†…å®¹è¿‡é•¿ ({len(cleaned_text)} å­—ç¬¦)ï¼Œæˆªå–å‰1000å­—ç¬¦")
            cleaned_text = cleaned_text[:1000] + "..."
        
        print(f"ğŸ“ å¼€å§‹AIå¤„ç†æ¨æ–‡ï¼ŒåŸå§‹é•¿åº¦: {len(tweet_text)}, å¤„ç†åé•¿åº¦: {len(cleaned_text)}")
        
        try:
            # ç¿»è¯‘æ¨æ–‡
            print("ğŸ”„ æ­£åœ¨ç¿»è¯‘æ¨æ–‡...")
            translate_prompt = f"""è¯·å°†ä»¥ä¸‹è‹±æ–‡æ¨æ–‡ç¿»è¯‘æˆä¸­æ–‡ï¼Œä¿æŒåŸæ„å’Œè¯­æ°”ï¼š

æ¨æ–‡å†…å®¹ï¼š{cleaned_text}

è¯·åªè¿”å›ç¿»è¯‘ç»“æœï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜ã€‚"""
            
            translation = self.get_ai_response(translate_prompt)
            print(f"âœ… ç¿»è¯‘å®Œæˆ: {translation[:50]}...")
            
            # è§£è¯»æ¨æ–‡
            print("ğŸ”„ æ­£åœ¨è§£è¯»æ¨æ–‡...")
            analysis_prompt = f"""è¯·å¯¹ä»¥ä¸‹æ¨æ–‡è¿›è¡Œæ·±åº¦è§£è¯»åˆ†æï¼ŒåŒ…æ‹¬å…¶å«ä¹‰ã€èƒŒæ™¯ã€å¯èƒ½çš„å½±å“ç­‰,å…¨æ–‡å†…å®¹åœ¨160å­—å·¦å³ï¼š

æ¨æ–‡å†…å®¹ï¼š{cleaned_text}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æï¼š
1. æ¨æ–‡çš„ä¸»è¦ä¿¡æ¯å’Œè§‚ç‚¹
2. å¯èƒ½çš„èƒŒæ™¯å’ŒåŸå› 
3. å¯¹ç›¸å…³é¢†åŸŸçš„å½±å“
4. å…¶ä»–å€¼å¾—å…³æ³¨çš„è¦ç‚¹

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå†…å®¹è¦æœ‰æ·±åº¦å’Œè§è§£ã€‚"""
            
            analysis = self.get_ai_response(analysis_prompt)
            print(f"âœ… è§£è¯»å®Œæˆ: {analysis[:50]}...")
            
            # ç”Ÿæˆæ ‡é¢˜
            print("ğŸ”„ æ­£åœ¨ç”Ÿæˆæ ‡é¢˜...")
            title_prompt = f"""è¯·ä¸ºä»¥ä¸‹æ¨æ–‡ç”Ÿæˆä¸€ä¸ªç®€æ´æœ‰åŠ›çš„ä¸­æ–‡æ ‡é¢˜ï¼Œè¦æ±‚ï¼š
1. æ§åˆ¶åœ¨15-25ä¸ªå­—ä»¥å†…
2. èƒ½å¤Ÿå‡†ç¡®æ¦‚æ‹¬æ¨æ–‡çš„æ ¸å¿ƒå†…å®¹
3. å…·æœ‰å¸å¼•åŠ›å’Œæ–°é—»æ€§

æ¨æ–‡å†…å®¹ï¼š{cleaned_text}

è¯·åªè¿”å›æ ‡é¢˜ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚"""
            
            title = self.get_ai_response(title_prompt)
            print(f"âœ… æ ‡é¢˜ç”Ÿæˆå®Œæˆ: {title}")
            
            # éªŒè¯AIå¤„ç†ç»“æœ
            if "AIå¤„ç†å¤±è´¥" in translation or "AIå¤„ç†å¤±è´¥" in analysis or "AIå¤„ç†å¤±è´¥" in title:
                print("âŒ AIå¤„ç†ç»“æœåŒ…å«é”™è¯¯ä¿¡æ¯")
                return {
                    'title': f"å¤„ç†å¼‚å¸¸: {title}",
                    'translation': f"ç¿»è¯‘å¼‚å¸¸: {translation}",
                    'analysis': f"è§£è¯»å¼‚å¸¸: {analysis}"
                }
            
            return {
                'title': title.strip(),
                'translation': translation.strip(),
                'analysis': analysis.strip()
            }
            
        except Exception as e:
            print(f"âŒ AIå¤„ç†è¿‡ç¨‹å‡ºç°å¼‚å¸¸: {str(e)}")
            return {
                'title': f"å¤„ç†å¼‚å¸¸: {str(e)[:50]}",
                'translation': f"ç¿»è¯‘å¼‚å¸¸: {str(e)[:50]}",
                'analysis': f"è§£è¯»å¼‚å¸¸: {str(e)[:50]}"
            }
    
    def preprocess_tweet_content(self, tweet_text: str) -> str:
        """
        é¢„å¤„ç†æ¨æ–‡å†…å®¹ï¼Œè¿‡æ»¤å¯èƒ½å¯¼è‡´å†…å®¹å®‰å…¨æ£€æŸ¥å¤±è´¥çš„å†…å®¹
        
        :param tweet_text: åŸå§‹æ¨æ–‡å†…å®¹
        :return: é¢„å¤„ç†åçš„å†…å®¹
        """
        if not tweet_text:
            return ""
        
        # è½¬æ¢ä¸ºå°å†™è¿›è¡Œæ£€æŸ¥
        text_lower = tweet_text.lower()
        
        # å®šä¹‰å¯èƒ½å¯¼è‡´å†…å®¹å®‰å…¨æ£€æŸ¥å¤±è´¥çš„è¯æ±‡æ¨¡å¼
        problematic_patterns = [
            # æ”¿æ²»æ•æ„Ÿè¯æ±‡ï¼ˆè‹±æ–‡ï¼‰
            r'\b(trump|biden|politics|government|election|vote|democrat|republican)\b',
            # æš´åŠ›ç›¸å…³è¯æ±‡
            r'\b(kill|death|murder|violence|attack|war|bomb|gun|weapon)\b',
            # è‰²æƒ…ç›¸å…³è¯æ±‡
            r'\b(sex|porn|nude|naked|sexual|adult)\b',
            # æ¯’å“ç›¸å…³è¯æ±‡
            r'\b(drug|heroin|cocaine|marijuana|weed|addiction)\b',
            # å…¶ä»–æ•æ„Ÿè¯æ±‡
            r'\b(hate|racist|discrimination|abuse|suicide)\b'
        ]
        
        import re
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«é—®é¢˜è¯æ±‡
        has_problematic_content = False
        for pattern in problematic_patterns:
            if re.search(pattern, text_lower):
                has_problematic_content = True
                print(f"âš ï¸ æ£€æµ‹åˆ°å¯èƒ½çš„é—®é¢˜å†…å®¹: {pattern}")
                break
        
        if has_problematic_content:
            # å¦‚æœæ£€æµ‹åˆ°é—®é¢˜å†…å®¹ï¼Œè¿›è¡Œå†…å®¹æ¸…ç†
            print("ğŸ§¹ æ­£åœ¨è¿›è¡Œå†…å®¹æ¸…ç†...")
            
            # æ›¿æ¢æ•æ„Ÿè¯æ±‡ä¸ºä¸­æ€§è¯æ±‡
            replacements = {
                r'\btrump\b': 'former president',
                r'\bbiden\b': 'current president',
                r'\bpolitics\b': 'public affairs',
                r'\bgovernment\b': 'administration',
                r'\belection\b': 'voting process',
                r'\bvote\b': 'participate',
                r'\bkill\b': 'eliminate',
                r'\bdeath\b': 'passing',
                r'\bmurder\b': 'incident',
                r'\bviolence\b': 'conflict',
                r'\battack\b': 'incident',
                r'\bwar\b': 'conflict',
                r'\bbomb\b': 'device',
                r'\bgun\b': 'weapon',
                r'\bweapon\b': 'tool',
                r'\bsex\b': 'relationship',
                r'\bporn\b': 'adult content',
                r'\bnude\b': 'unclothed',
                r'\bnaked\b': 'unclothed',
                r'\bsexual\b': 'intimate',
                r'\badult\b': 'mature',
                r'\bdrug\b': 'substance',
                r'\bheroin\b': 'illegal substance',
                r'\bcocaine\b': 'illegal substance',
                r'\bmarijuana\b': 'cannabis',
                r'\bweed\b': 'cannabis',
                r'\baddiction\b': 'dependency',
                r'\bhate\b': 'dislike',
                r'\bracist\b': 'discriminatory',
                r'\bdiscrimination\b': 'bias',
                r'\babuse\b': 'mistreatment',
                r'\bsuicide\b': 'self-harm'
            }
            
            cleaned_text = tweet_text
            for pattern, replacement in replacements.items():
                cleaned_text = re.sub(pattern, replacement, cleaned_text, flags=re.IGNORECASE)
            
            print(f"âœ… å†…å®¹æ¸…ç†å®Œæˆï¼ŒåŸå§‹é•¿åº¦: {len(tweet_text)}, æ¸…ç†åé•¿åº¦: {len(cleaned_text)}")
            return cleaned_text
        
        return tweet_text
    
    def get_tweets_from_account(self, account: str, since_time: datetime, until_time: datetime, exclude_replies: bool = False) -> list:
        """
        è·å–æŒ‡å®šè´¦å·åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ¨æ–‡
        
        :param account: Twitterè´¦å·
        :param since_time: å¼€å§‹æ—¶é—´
        :param until_time: ç»“æŸæ—¶é—´
        :param exclude_replies: æ˜¯å¦æ’é™¤å›å¤æ¨æ–‡
        :return: æ¨æ–‡åˆ—è¡¨
        """
        since_str = since_time.strftime("%Y-%m-%dT%H:%M:%SZ")
        until_str = until_time.strftime("%Y-%m-%dT%H:%M:%SZ")
        
        # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦æ’é™¤å›å¤
        if exclude_replies:
            query = f"from:{account} -is:reply since:{since_str} until:{until_str} include:nativeretweets"
        else:
            query = f"from:{account} since:{since_str} until:{until_str} include:nativeretweets"
            
        url = "https://api.twitterapi.io/twitter/tweet/advanced_search"
        params = {"query": query, "queryType": "Latest"}
        headers = {"X-API-Key": self.twitter_api_key}
        
        all_tweets = []
        next_cursor = None
        
        while True:
            if next_cursor:
                params["cursor"] = next_cursor
            
            response = requests.get(url, headers=headers, params=params, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                tweets = data.get("tweets", [])
                
                if tweets:
                    for t in tweets:
                        t['author'] = account  # æ·»åŠ ä½œè€…ä¿¡æ¯
                    all_tweets.extend(tweets)
                
                if data.get("has_next_page", False) and data.get("next_cursor", "") != "":
                    next_cursor = data.get("next_cursor")
                    continue
                else:
                    break
            else:
                print(f"è·å–æ¨æ–‡å‡ºé”™: {response.status_code} - {response.text}")
                break
        
        return all_tweets
    
    def save_tweet_data(self, tweet_data: dict):
        """
        ä¿å­˜æ¨æ–‡æ•°æ®åˆ°JSONæ–‡ä»¶ï¼ŒæŒ‰å¤©å­˜å‚¨
        
        :param tweet_data: æ¨æ–‡æ•°æ®
        """
        today = datetime.now().strftime("%Y-%m-%d")
        file_path = os.path.join(self.data_dir, f"tweets_{today}.json")
        
        # è¯»å–ç°æœ‰æ•°æ®
        existing_data = []
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
            except json.JSONDecodeError:
                existing_data = []
        
        # æ£€æŸ¥æ˜¯å¦é‡å¤ - æ ¹æ®æ¨æ–‡IDå»é‡
        tweet_id = tweet_data.get('id')
        existing_ids = {item.get('id') for item in existing_data if item.get('id')}
        
        if tweet_id not in existing_ids:
            # æ·»åŠ æ–°æ•°æ®ï¼ˆä»…å½“IDä¸é‡å¤æ—¶ï¼‰
            existing_data.append(tweet_data)
            print(f"ä¿å­˜æ–°æ¨æ–‡: {tweet_id} - {tweet_data.get('author', 'Unknown')}")
            
            # å†™å…¥æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(existing_data, f, ensure_ascii=False, indent=2)
            
            # å‘é€é’‰é’‰æ¨é€
            if self.enable_dingtalk and self.dingtalk_webhook and self.dingtalk_secret:
                try:
                    self.send_dingtalk_notification(tweet_data)
                except Exception as e:
                    print(f"é’‰é’‰æ¨é€å¤±è´¥: {str(e)}")
        else:
            print(f"è·³è¿‡é‡å¤æ¨æ–‡: {tweet_id} - {tweet_data.get('author', 'Unknown')}")
    
    def send_dingtalk_notification(self, tweet_data: dict):
        """
        å‘é€é’‰é’‰æœºå™¨äººé€šçŸ¥
        
        :param tweet_data: æ¨æ–‡æ•°æ®
        """
        try:
            import hmac
            import hashlib
            import base64
            import urllib.parse
            import requests
            
            # æ„å»ºæ¶ˆæ¯å†…å®¹
            author = tweet_data.get('author', 'Unknown')
            original_created_at_str = tweet_data.get('created_at', '') # è·å–åŸå§‹æ¨æ–‡åˆ›å»ºæ—¶é—´å­—ç¬¦ä¸²
            ai_title = tweet_data.get('ai_title', '')
            ai_content = tweet_data.get('ai_translation', '')
            original_text = tweet_data.get('original_text', '')
            
            # æ£€æŸ¥AIå¤„ç†æ˜¯å¦æˆåŠŸï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨åŸæ–‡
            ai_processing_failed = False
            if (ai_title and ("å¤„ç†å¤±è´¥" in ai_title or "å†…å®¹å®‰å…¨æ£€æŸ¥å¤±è´¥" in ai_title or "AIæ ‡é¢˜ç”Ÿæˆå¤±è´¥" in ai_title)):
                ai_processing_failed = True
            if (ai_content and ("å¤„ç†å¤±è´¥" in ai_content or "å†…å®¹å®‰å…¨æ£€æŸ¥å¤±è´¥" in ai_content)):
                ai_processing_failed = True
            
            # å¦‚æœAIå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡å†…å®¹
            if ai_processing_failed:
                ai_title = "AIå¤„ç†å¤±è´¥ï¼Œæ˜¾ç¤ºåŸæ–‡"
                ai_content = f"**æ¨æ–‡åŸæ–‡ï¼š**\n{original_text}"
                print(f"âš ï¸ AIå¤„ç†å¤±è´¥ï¼Œé’‰é’‰æ¨é€å°†æ˜¾ç¤ºåŸæ–‡å†…å®¹")
            
            # ç¡®ä¿æœ‰å†…å®¹æ˜¾ç¤º
            if not ai_content:
                ai_content = f"**æ¨æ–‡åŸæ–‡ï¼š**\n{original_text[:200]}{'...' if len(original_text) > 200 else ''}"
            
            if not ai_title:
                ai_title = 'AIæ ‡é¢˜ç”Ÿæˆå¤±è´¥ï¼Œæ˜¾ç¤ºåŸæ–‡'
            
            # æ ¼å¼åŒ–æ¨æ–‡å‘å¸–æ—¶é—´ä¸ºåŒ—äº¬æ—¶é—´
            formatted_tweet_posting_time = "æœªçŸ¥æ—¶é—´"
            try:
                if original_created_at_str:
                    from email.utils import parsedate_to_datetime
                    utc_time = parsedate_to_datetime(original_created_at_str)
                    beijing_time = utc_time + timedelta(hours=8)
                    formatted_tweet_posting_time = beijing_time.strftime("%Y-%m-%d %H:%M:%S")
            except Exception as e:
                print(f"âŒ é’‰é’‰é€šçŸ¥æ—¶é—´è§£æé”™è¯¯: {str(e)}")
                formatted_tweet_posting_time = "æœªçŸ¥æ—¶é—´"
            
            message = f"""# ğŸ¤– AIæ–°é—»æ¨é€

---

## ğŸ“ **ä½œè€…ï¼š** {author}
â° **å‘å¸–æ—¶é—´ï¼š** {formatted_tweet_posting_time}

ğŸ¯ **AIç”Ÿæˆæ ‡é¢˜ï¼š** **{ai_title}**

## ğŸ§  **AIç¿»è¯‘å†…å®¹ï¼š**
{ai_content}

---

ğŸ’¡ *ç”± Twitter(X) AI ç›‘æ§ç³»ç»Ÿ è‡ªåŠ¨æ¨é€*"""
            
            # è®¡ç®—ç­¾å
            timestamp = str(int(time.time() * 1000))
            string_to_sign = f'{timestamp}\n{self.dingtalk_secret}'
            hmac_code = hmac.new(
                self.dingtalk_secret.encode('utf-8'),
                string_to_sign.encode('utf-8'),
                digestmod=hashlib.sha256
            ).digest()
            sign = urllib.parse.quote_plus(base64.b64encode(hmac_code))
            
            # æ„å»ºè¯·æ±‚URL
            url = f"{self.dingtalk_webhook}&timestamp={timestamp}&sign={sign}"
            
            # æ„å»ºæ¶ˆæ¯æ•°æ®
            data = {
                "msgtype": "markdown",
                "markdown": {
                    "title": f"ğŸ¤– AIæ–°é—»æ¨é€ - {author}",
                    "text": message
                },
                "at": {
                    "isAtAll": False
                }
            }
            
            # å‘é€è¯·æ±‚
            response = requests.post(url, json=data, timeout=10)
            
            if response.status_code == 200:
                result = response.json()
                if result.get('errcode') == 0:
                    print(f"âœ… é’‰é’‰æ¶ˆæ¯å‘é€æˆåŠŸ: {author}")
                else:
                    print(f"âŒ é’‰é’‰æ¶ˆæ¯å‘é€å¤±è´¥: {result.get('errmsg')}")
            else:
                print(f"âŒ é’‰é’‰è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                
        except Exception as e:
            print(f"âŒ é’‰é’‰æ¶ˆæ¯å‘é€å¼‚å¸¸: {str(e)}")
    
    def load_tweets_by_date(self, date_str: str = None) -> list:
        """
        æ ¹æ®æ—¥æœŸåŠ è½½æ¨æ–‡æ•°æ®
        
        :param date_str: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºä»Šå¤©
        :return: æ¨æ–‡æ•°æ®åˆ—è¡¨
        """
        if date_str is None:
            date_str = datetime.now().strftime("%Y-%m-%d")
        
        file_path = os.path.join(self.data_dir, f"tweets_{date_str}.json")
        
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except json.JSONDecodeError:
                return []
        return []
    
    def get_all_tweets(self) -> list:
        """
        è·å–æ‰€æœ‰å­˜å‚¨çš„æ¨æ–‡æ•°æ®
        
        :return: æ‰€æœ‰æ¨æ–‡æ•°æ®åˆ—è¡¨
        """
        all_tweets = []
        
        # éå†æ•°æ®ç›®å½•ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶
        if os.path.exists(self.data_dir):
            for filename in os.listdir(self.data_dir):
                if filename.startswith("tweets_") and filename.endswith(".json"):
                    file_path = os.path.join(self.data_dir, filename)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            tweets = json.load(f)
                            all_tweets.extend(tweets)
                    except json.JSONDecodeError:
                        continue
        
        # æŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        all_tweets.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        return all_tweets
    
    def monitor_and_process(self, target_accounts: list, check_interval: int = 300, hours: int = 1, exclude_replies: bool = False):
        """
        ç›‘æ§Twitterè´¦å·å¹¶ä½¿ç”¨AIå¤„ç†æ–°æ¨æ–‡
        
        :param target_accounts: è¦ç›‘æ§çš„è´¦å·åˆ—è¡¨
        :param check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        :param hours: åˆå§‹å›æº¯æ—¶é—´ï¼ˆå°æ—¶ï¼‰
        :param exclude_replies: æ˜¯å¦æ’é™¤å›å¤æ¨æ–‡
        """
        last_checked_time = datetime.utcnow() - timedelta(hours=hours)
        
        def check_and_process_tweets():
            nonlocal last_checked_time
            until_time = datetime.utcnow()
            since_time = last_checked_time
            
            all_tweets = []
            
            for account in target_accounts:
                tweets = self.get_tweets_from_account(account, since_time, until_time, exclude_replies)
                all_tweets.extend(tweets)
                
                # æ·»åŠ 5ç§’å»¶è¿Ÿï¼Œé¿å…APIé™åˆ¶
                if account != target_accounts[-1]:  # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªè´¦å·ï¼Œæ·»åŠ å»¶è¿Ÿ
                    print("ç­‰å¾…5ç§’ï¼Œé¿å…APIè¯·æ±‚é™åˆ¶...")
                    time.sleep(5)
            
            if all_tweets:
                print(f"å‘ç° {len(all_tweets)} æ¡æ–°æ¨æ–‡ï¼Œå¼€å§‹AIå¤„ç†...\n")
                
                for idx, tweet in enumerate(all_tweets, start=1):
                    print(f"{'='*60}")
                    print(f"å¤„ç†æ¨æ–‡ {idx}/{len(all_tweets)}")
                    print(f"{'='*60}")
                    
                    # åŸºæœ¬ä¿¡æ¯
                    tweet_id = tweet.get('id') or tweet.get('id_str')
                    tweet_url = f"https://twitter.com/{tweet['author']}/status/{tweet_id}"
                    original_text = tweet.get('text', '')
                    
                    print(f"ä½œè€…ï¼š{tweet['author']}")
                    print(f"å‘å¸ƒæ—¶é—´ï¼š{tweet.get('createdAt')}")
                    print(f"åŸæ–‡ï¼š{original_text}")
                    print(f"é“¾æ¥ï¼š{tweet_url}")
                    print()
                    
                    # AIå¤„ç†
                    try:
                        print(f"ğŸ§  å¼€å§‹AIå¤„ç†æ¨æ–‡ {idx}/{len(all_tweets)}")
                        ai_result = self.process_tweet_with_ai(original_text)
                        
                        # æ£€æŸ¥AIå¤„ç†ç»“æœè´¨é‡
                        if any("å¤„ç†å¼‚å¸¸" in str(v) or "ç¿»è¯‘å¼‚å¸¸" in str(v) or "è§£è¯»å¼‚å¸¸" in str(v) for v in ai_result.values()):
                            print(f"âš ï¸ AIå¤„ç†ç»“æœè´¨é‡ä¸ä½³ï¼Œæ¨æ–‡ID: {tweet_id}")
                            # å¯ä»¥é€‰æ‹©è·³è¿‡ä¿å­˜æˆ–æ ‡è®°ä¸ºä½è´¨é‡
                        
                    except Exception as e:
                        print(f"âŒ AIå¤„ç†æ¨æ–‡å¤±è´¥: {str(e)}")
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯å†…å®¹å®‰å…¨æ£€æŸ¥å¤±è´¥
                        if "data_inspection_failed" in str(e).lower() or "inappropriate content" in str(e).lower():
                            print("ğŸš« å†…å®¹å®‰å…¨æ£€æŸ¥å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨å¤„ç†ç­–ç•¥...")
                            # ä½¿ç”¨å¤‡ç”¨ç­–ç•¥ï¼šç®€å•çš„å…³é”®è¯æå–å’ŒåŸºæœ¬ç¿»è¯‘
                            ai_result = self.fallback_processing(original_text)
                        else:
                            ai_result = {
                                'title': f"å¤„ç†å¤±è´¥: {str(e)[:50]}",
                                'translation': f"åŸæ–‡: {original_text[:100]}{'...' if len(original_text) > 100 else ''}",
                                'analysis': f"AIå¤„ç†å¤±è´¥: {str(e)}"
                            }
                    
                    print(f"AIæ ‡é¢˜ï¼š{ai_result['title']}")
                    print(f"AIç¿»è¯‘ï¼š{ai_result['translation']}")
                    print(f"AIè§£è¯»ï¼š{ai_result['analysis']}")
                    print(f"{'='*60}\n")
                    
                    # ä¿å­˜æ•°æ®åˆ°JSON
                    tweet_data = {
                        'id': tweet_id,
                        'author': tweet['author'],
                        'created_at': tweet.get('createdAt'),
                        'original_text': original_text,
                        'tweet_url': tweet_url,
                        'ai_title': ai_result['title'],
                        'ai_translation': ai_result['translation'],
                        'ai_analysis': ai_result['analysis'],
                        'timestamp': datetime.utcnow().isoformat(),
                        'processed_date': datetime.now().strftime("%Y-%m-%d")
                    }
                    self.save_tweet_data(tweet_data)
                    
                    # æ·»åŠ å»¶è¿Ÿé¿å…APIé¢‘ç‡é™åˆ¶
                    time.sleep(2)
            else:
                print(f"{datetime.utcnow()} - æ²¡æœ‰å‘ç°æ–°æ¨æ–‡ã€‚")
            
            last_checked_time = until_time
        
        print(f"å¼€å§‹ç›‘æ§è´¦å·: {', '.join(target_accounts)}")
        print(f"æ£€æŸ¥é—´éš”: {check_interval} ç§’")
        print(f"AIå¤„ç†åŠŸèƒ½å·²å¯ç”¨\n")
        
        try:
            while True:
                check_and_process_tweets()
                print(f"ç­‰å¾… {check_interval} ç§’åè¿›è¡Œä¸‹æ¬¡æ£€æŸ¥...")
                time.sleep(check_interval)
        except KeyboardInterrupt:
            print("ç›‘æ§å·²åœæ­¢ã€‚")
    
    def monitor_and_process_with_status(self, target_accounts: list, check_interval: int = 300, hours: int = 1, status_dict: dict = None, exclude_replies: bool = False):
        """
        å¸¦çŠ¶æ€æ›´æ–°çš„ç›‘æ§åŠŸèƒ½
        
        :param target_accounts: è¦ç›‘æ§çš„è´¦å·åˆ—è¡¨
        :param check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        :param hours: åˆå§‹å›æº¯æ—¶é—´ï¼ˆå°æ—¶ï¼‰
        :param status_dict: çŠ¶æ€å­—å…¸ï¼Œç”¨äºæ›´æ–°å‰ç«¯æ˜¾ç¤º
        :param exclude_replies: æ˜¯å¦æ’é™¤å›å¤æ¨æ–‡
        """
        last_checked_time = datetime.utcnow() - timedelta(hours=hours)
        
        def update_status(status, account="", result=""):
            if status_dict:
                status_dict["current_status"] = status
                status_dict["current_account"] = account
                status_dict["last_update"] = datetime.now().isoformat()
                if result:
                    status_dict["last_result"] = result
                # è®¡ç®—ä¸‹æ¬¡æ£€æŸ¥æ—¶é—´
                next_time = datetime.now() + timedelta(seconds=check_interval)
                status_dict["next_check_time"] = next_time.isoformat()
        
        def check_and_process_tweets():
            nonlocal last_checked_time
            until_time = datetime.utcnow()
            since_time = last_checked_time
            
            all_tweets = []
            
            try:
                # æ›´æ–°çŠ¶æ€ï¼šå¼€å§‹æŠ“å–
                update_status("ğŸ” æ‰«æä¸­", f"{', '.join(target_accounts)}")
                
                for account in target_accounts:
                    try:
                        update_status(f"ğŸ“¡ æ­£åœ¨æŠ“å– @{account} çš„æ¨æ–‡...")
                        tweets = self.get_tweets_from_account(account, since_time, until_time, exclude_replies)
                        all_tweets.extend(tweets)
                        print(f"âœ… æˆåŠŸè·å– @{account} çš„ {len(tweets)} æ¡æ¨æ–‡")
                        
                        # æ·»åŠ 5ç§’å»¶è¿Ÿï¼Œé¿å…APIé™åˆ¶
                        if account != target_accounts[-1]:  # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªè´¦å·ï¼Œæ·»åŠ å»¶è¿Ÿ
                            print("ç­‰å¾…5ç§’ï¼Œé¿å…APIè¯·æ±‚é™åˆ¶...")
                            time.sleep(5)
                            
                    except Exception as e:
                        print(f"âŒ è·å– @{account} æ¨æ–‡å¤±è´¥: {str(e)}")
                        update_status(f"âš ï¸ @{account} æ•°æ®è·å–å¼‚å¸¸", result=f"é”™è¯¯: {str(e)}")
                        continue
            except Exception as e:
                print(f"âŒ æ¨æ–‡æ‰«æè¿‡ç¨‹å‡ºé”™: {str(e)}")
                update_status(f"âš ï¸ æ‰«æè¿‡ç¨‹å¼‚å¸¸", result=f"é”™è¯¯: {str(e)}")
                return
            
            if all_tweets:
                update_status(f"ğŸ¤– å‘ç° {len(all_tweets)} æ¡æ–°æ¨æ–‡ï¼ŒAIåˆ†æä¸­...", result=f"æ‰¾åˆ° {len(all_tweets)} æ¡æ–°æ¨æ–‡")
                
                for idx, tweet in enumerate(all_tweets, start=1):
                    # åŸºæœ¬ä¿¡æ¯
                    tweet_id = tweet.get('id') or tweet.get('id_str')
                    tweet_url = f"https://twitter.com/{tweet['author']}/status/{tweet_id}"
                    original_text = tweet.get('text', '')
                    
                    # æ›´æ–°çŠ¶æ€ï¼šAIå¤„ç†ä¸­
                    update_status(f"ğŸ§  AIå¤„ç†ä¸­... ({idx}/{len(all_tweets)})", f"@{tweet['author']}")
                    
                    # AIå¤„ç†
                    try:
                        print(f"ğŸ§  å¼€å§‹AIå¤„ç†æ¨æ–‡ {idx}/{len(all_tweets)}")
                        ai_result = self.process_tweet_with_ai(original_text)
                        
                        # æ£€æŸ¥AIå¤„ç†ç»“æœè´¨é‡
                        if any("å¤„ç†å¼‚å¸¸" in str(v) or "ç¿»è¯‘å¼‚å¸¸" in str(v) or "è§£è¯»å¼‚å¸¸" in str(v) for v in ai_result.values()):
                            print(f"âš ï¸ AIå¤„ç†ç»“æœè´¨é‡ä¸ä½³ï¼Œæ¨æ–‡ID: {tweet_id}")
                            # å¯ä»¥é€‰æ‹©è·³è¿‡ä¿å­˜æˆ–æ ‡è®°ä¸ºä½è´¨é‡
                        
                    except Exception as e:
                        print(f"âŒ AIå¤„ç†æ¨æ–‡å¤±è´¥: {str(e)}")
                        ai_result = {
                            'title': f"å¤„ç†å¤±è´¥: {str(e)[:50]}",
                            'translation': f"åŸæ–‡: {original_text[:100]}{'...' if len(original_text) > 100 else ''}",
                            'analysis': f"AIå¤„ç†å¤±è´¥: {str(e)}"
                        }
                    
                    # ä¿å­˜æ•°æ®åˆ°JSON
                    tweet_data = {
                        'id': tweet_id,
                        'author': tweet['author'],
                        'created_at': tweet.get('createdAt'),
                        'original_text': original_text,
                        'tweet_url': tweet_url,
                        'ai_title': ai_result['title'],
                        'ai_translation': ai_result['translation'],
                        'ai_analysis': ai_result['analysis'],
                        'timestamp': datetime.utcnow().isoformat(),
                        'processed_date': datetime.now().strftime("%Y-%m-%d")
                    }
                    self.save_tweet_data(tweet_data)
                    
                    # æ›´æ–°å¤„ç†è®¡æ•°
                    if status_dict:
                        status_dict["processed_tweets"] = status_dict.get("processed_tweets", 0) + 1
                    
                    # æ·»åŠ å»¶è¿Ÿé¿å…APIé¢‘ç‡é™åˆ¶
                    time.sleep(2)
                
                update_status("âœ… å¤„ç†å®Œæˆ", result=f"æˆåŠŸå¤„ç† {len(all_tweets)} æ¡æ¨æ–‡")
            else:
                update_status("â­ æ™ºèƒ½å¾…æœºä¸­", result="æœªå‘ç°æ–°æ¨æ–‡ï¼Œç»§ç»­ç›‘æ§ä¸­...")
            
            last_checked_time = until_time
        
        update_status("ğŸš€ Neural Network å·²å¯åŠ¨", f"ç›‘æ§ {len(target_accounts)} ä¸ªè´¦å·")
        print(f"ğŸš€ ç›‘æ§å¯åŠ¨æˆåŠŸï¼Œç›®æ ‡è´¦å·: {target_accounts}")
        
        try:
            while status_dict and status_dict.get("running", False):
                print(f"ğŸ”„ å¼€å§‹æ–°ä¸€è½®æ£€æŸ¥å¾ªç¯...")
                check_and_process_tweets()
                
                # å€’è®¡æ—¶ç­‰å¾…
                for remaining in range(check_interval, 0, -10):
                    if not status_dict.get("running", False):
                        print("ğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡ºç›‘æ§")
                        break
                    update_status(f"â±ï¸ ä¸‹æ¬¡æ‰«æå€’è®¡æ—¶ {remaining}s", result=status_dict.get("last_result", ""))
                    time.sleep(10)
                    
        except KeyboardInterrupt:
            print("ğŸ›‘ ç›‘æ§è¢«ä¸­æ–­")
            update_status("ğŸ›‘ Neural Network å·²åœæ­¢")
        except Exception as e:
            print(f"âŒ ç›‘æ§è¿‡ç¨‹å‡ºç°å¼‚å¸¸: {str(e)}")
            update_status("âŒ ç›‘æ§å¼‚å¸¸åœæ­¢", result=f"é”™è¯¯: {str(e)}")
            if status_dict:
                status_dict["running"] = False

    def fallback_processing(self, tweet_text: str) -> dict:
        """
        å¤‡ç”¨å¤„ç†ç­–ç•¥ï¼šå½“AIå¤„ç†å¤±è´¥æ—¶ï¼Œæä¾›åŸºæœ¬çš„ä¿¡æ¯æå–
        
        :param tweet_text: æ¨æ–‡å†…å®¹
        :return: åŸºæœ¬çš„å¤„ç†ç»“æœ
        """
        print("ğŸ”„ å¯ç”¨å¤‡ç”¨å¤„ç†ç­–ç•¥...")
        
        try:
            # ç®€å•çš„å…³é”®è¯æå–
            import re
            
            # æå–URL
            urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', tweet_text)
            
            # æå–@ç”¨æˆ·å
            usernames = re.findall(r'@(\w+)', tweet_text)
            
            # æå–#è¯é¢˜æ ‡ç­¾
            hashtags = re.findall(r'#(\w+)', tweet_text)
            
            # æå–æ•°å­—
            numbers = re.findall(r'\d+', tweet_text)
            
            # ç®€å•çš„é•¿åº¦ç»Ÿè®¡
            word_count = len(tweet_text.split())
            char_count = len(tweet_text)
            
            # ç”ŸæˆåŸºæœ¬ä¿¡æ¯
            title = f"æ¨æ–‡åˆ†æ (å¤‡ç”¨å¤„ç†)"
            
            # ç”ŸæˆåŸºæœ¬ç¿»è¯‘ï¼ˆä¿æŒåŸæ–‡ï¼Œæ·»åŠ è¯´æ˜ï¼‰
            translation = f"åŸæ–‡å†…å®¹: {tweet_text[:200]}{'...' if len(tweet_text) > 200 else ''}"
            
            # ç”ŸæˆåŸºæœ¬åˆ†æ
            analysis_parts = []
            if urls:
                analysis_parts.append(f"åŒ…å«é“¾æ¥: {len(urls)} ä¸ª")
            if usernames:
                analysis_parts.append(f"æåŠç”¨æˆ·: {', '.join(usernames)}")
            if hashtags:
                analysis_parts.append(f"è¯é¢˜æ ‡ç­¾: {', '.join(hashtags)}")
            if numbers:
                analysis_parts.append(f"æ•°å­—ä¿¡æ¯: {', '.join(numbers)}")
            
            analysis_parts.append(f"æ–‡æœ¬é•¿åº¦: {word_count} è¯, {char_count} å­—ç¬¦")
            
            analysis = f"å¤‡ç”¨åˆ†æç»“æœ: {'; '.join(analysis_parts)}ã€‚ç”±äºå†…å®¹å®‰å…¨æ£€æŸ¥å¤±è´¥ï¼Œæ— æ³•è¿›è¡ŒAIæ·±åº¦åˆ†æã€‚"
            
            print("âœ… å¤‡ç”¨å¤„ç†å®Œæˆ")
            return {
                'title': title,
                'translation': translation,
                'analysis': analysis
            }
            
        except Exception as e:
            print(f"âŒ å¤‡ç”¨å¤„ç†ä¹Ÿå¤±è´¥: {str(e)}")
            return {
                'title': 'å¤„ç†å¤±è´¥',
                'translation': f'åŸæ–‡: {tweet_text[:100]}{"..." if len(tweet_text) > 100 else ""}',
                'analysis': f'AIå¤„ç†å’Œå¤‡ç”¨å¤„ç†å‡å¤±è´¥: {str(e)}'
            }


# ä¸»ç¨‹åº
if __name__ == "__main__":
    # ä»é…ç½®æ–‡ä»¶åŠ è½½é…ç½®
    config_file = "config.json"
    
    # é»˜è®¤é…ç½®
    default_config = {
        "TWITTER_API_KEY": "b74c1eefe1004xxx3c6b82c4ee5",
        "LLM_URL": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "LLM_API_KEY": "sk-bf2a9bf3xxxb344d8bbe5fbdc",
        "TARGET_ACCOUNTS": ["OpenAI"],
        "CHECK_INTERVAL": 300,
        "INITIAL_HOURS": 64,
        "EXCLUDE_REPLIES": False, # æ–°å¢é…ç½®é¡¹
        "DINGTALK_WEBHOOK": "", # æ–°å¢é…ç½®é¡¹
        "DINGTALK_SECRET": "", # æ–°å¢é…ç½®é¡¹
        "ENABLE_DINGTALK": False # æ–°å¢é…ç½®é¡¹
    }
    
    # è¯»å–é…ç½®æ–‡ä»¶
    if os.path.exists(config_file):
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                # åˆå¹¶é»˜è®¤é…ç½®
                for key, value in default_config.items():
                    if key not in config:
                        config[key] = value
        except Exception as e:
            print(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            config = default_config
    else:
        print("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        config = default_config
    
    # æå–é…ç½®å‚æ•°
    TWITTER_API_KEY = config["TWITTER_API_KEY"]
    LLM_URL = config["LLM_URL"]
    LLM_API_KEY = config["LLM_API_KEY"]
    TARGET_ACCOUNTS = config["TARGET_ACCOUNTS"]
    CHECK_INTERVAL = config["CHECK_INTERVAL"]
    INITIAL_HOURS = config["INITIAL_HOURS"]
    EXCLUDE_REPLIES = config["EXCLUDE_REPLIES"] # ä»é…ç½®åŠ è½½
    DINGTALK_WEBHOOK = config["DINGTALK_WEBHOOK"]
    DINGTALK_SECRET = config["DINGTALK_SECRET"]
    ENABLE_DINGTALK = config["ENABLE_DINGTALK"]
    
    print(f"å¼€å§‹ç›‘æ§è´¦å·: {', '.join(TARGET_ACCOUNTS)}")
    print(f"æ£€æŸ¥é—´éš”: {CHECK_INTERVAL}ç§’")
    print(f"åˆå§‹å›æº¯: {INITIAL_HOURS}å°æ—¶")
    print(f"æ˜¯å¦æ’é™¤å›å¤: {EXCLUDE_REPLIES}") # æ‰“å°é…ç½®
    print(f"æ˜¯å¦å¯ç”¨é’‰é’‰æ¨é€: {ENABLE_DINGTALK}") # æ‰“å°é…ç½®
    
    # åˆ›å»ºç›‘æ§å™¨å¹¶å¼€å§‹ç›‘æ§
    monitor = TwitterAIMonitor(TWITTER_API_KEY, LLM_URL, LLM_API_KEY, 
                                dingtalk_webhook=DINGTALK_WEBHOOK, 
                                dingtalk_secret=DINGTALK_SECRET, 
                                enable_dingtalk=ENABLE_DINGTALK)
    monitor.monitor_and_process(TARGET_ACCOUNTS, CHECK_INTERVAL, INITIAL_HOURS, EXCLUDE_REPLIES) 